{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1403617d-2a00-48ca-8bdd-0a65beb34238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1+cu117'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "82d5f25e-aa92-4d67-8715-408cbfe83a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50_0_0_20170117135034485.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>55_0_3_20170119171117830.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12_0_4_20170103201607807.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40_0_0_20170117172519480.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>39_1_3_20170104233629347.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23703</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65_0_0_20170111200641250.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23704</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26_1_0_20170116234741431.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23705</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55_0_0_20170120140655585.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23706</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60_1_0_20170110122614299.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23707</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38_0_1_20170116200942002.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23705 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age gender race                                   path\n",
       "0        5      0    0  50_0_0_20170117135034485.jpg.chip.jpg\n",
       "1        5      0    3  55_0_3_20170119171117830.jpg.chip.jpg\n",
       "2        1      0    4  12_0_4_20170103201607807.jpg.chip.jpg\n",
       "3        4      0    0  40_0_0_20170117172519480.jpg.chip.jpg\n",
       "4        3      1    3  39_1_3_20170104233629347.jpg.chip.jpg\n",
       "...    ...    ...  ...                                    ...\n",
       "23703    6      0    0  65_0_0_20170111200641250.jpg.chip.jpg\n",
       "23704    2      1    0  26_1_0_20170116234741431.jpg.chip.jpg\n",
       "23705    5      0    0  55_0_0_20170120140655585.jpg.chip.jpg\n",
       "23706    6      1    0  60_1_0_20170110122614299.jpg.chip.jpg\n",
       "23707    3      0    1  38_0_1_20170116200942002.jpg.chip.jpg\n",
       "\n",
       "[23705 rows x 4 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from helper import get_dataframe\n",
    "\n",
    "df = get_dataframe('UTKFace')\n",
    "\n",
    "valid_values = ['0', '1', '2', '3', '4']\n",
    "\n",
    "df= df[df['race'].isin(valid_values)]\n",
    "\n",
    "def f(x):\n",
    "    return int(int(x)/10)\n",
    "\n",
    "df['age'] = df['age'].apply(lambda x: f(x))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2cc92b19-5a41-45cd-932f-90ca5ff7ecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating custom dataset\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, path, labels, transform=None):\n",
    "        self.img_dir = path\n",
    "        self.img_labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        \n",
    "        # Convert the 'age' value to an integer\n",
    "        label = int(self.img_labels.iloc[idx, 1])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# Here normalization component was a standard found from the internet\n",
    "\n",
    "transform = transforms.Compose([  \n",
    "    transforms.ToPILImage(),\n",
    "    # transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((32, 32)),  # Resize the image to 28x28 pixels\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean=[0.485], std=[0.229])  # Normalize image (for grayscale)\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e88203ad-4a8b-4243-9456-1f69207301d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  5,  1,  3,  4,  0, 11,  6,  7,  9,  8, 10])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['path'], df['age'], test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "training_data = pd.concat([X_train,y_train],axis=1)\n",
    "\n",
    "testing_data = pd.concat([X_test,y_test],axis=1)\n",
    "\n",
    "training_data['age'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f59c6a09-0862-4783-9bf9-6ac4c5f94bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = CustomDataset('UTKFace', training_data, transform)\n",
    "testing_dataset = CustomDataset('UTKFace', testing_data, transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3fc3fcd1-8b4e-47a5-b39d-0931442451c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(testing_dataset, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1df0f123-fcfb-4cbb-ba09-5370a79dc339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 32, 32])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))[0].shape# Test column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce52dfda-db90-41f7-a1c2-30a5810942d2",
   "metadata": {},
   "source": [
    "### Creating TinyVGG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8650c881-2ce2-4bab-a01f-fa2e424c74c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "  def __init__(self,input_shape:int,hidden_units:int,output_shape:int):\n",
    "    super().__init__()\n",
    "    self.conv_block_1 = nn.Sequential(\n",
    "        nn.Conv2d(input_shape,hidden_units,kernel_size = 3,stride = 1,padding = 1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(hidden_units,hidden_units,kernel_size=3,stride=1,padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=3)\n",
    "    )\n",
    "\n",
    "    self.conv_block_2 = nn.Sequential(\n",
    "        nn.Conv2d(hidden_units,hidden_units,kernel_size = 3,stride = 1,padding = 1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(hidden_units,hidden_units,kernel_size=3,stride=1,padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2)\n",
    "    )\n",
    "\n",
    "    self.classifier = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(in_features=25*10,\n",
    "                  out_features=output_shape)\n",
    "    )\n",
    "\n",
    "\n",
    "  def forward(self,x):\n",
    "\n",
    "    x = self.conv_block_1(x)\n",
    "    x = self.conv_block_2(x)\n",
    "    x = self.classifier(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "57292e6a-aa8e-4122-bdf3-cad6deff6abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d64f1e63-26b5-4aaf-9e27-482b5fd163d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating model and defining function\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = 'cpu'\n",
    "model = Model(3,10,12)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params = model.parameters(),\n",
    "                            lr=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f39c1090-08fb-4f31-b428-2a0af7f18d62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97c1ce6519d645a4be0799f6ec3ed652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 0/593 samples.\n",
      "Looked at 12800/593 samples.\n",
      "Train loss:1.3995872735977173\n",
      "Test acc : 46.16610738255034 | test loss : 1.379460334777832 | Train loss : 1.3995872735977173\n",
      "Looked at 0/593 samples.\n",
      "Looked at 12800/593 samples.\n",
      "Train loss:1.3560317754745483\n",
      "Test acc : 45.56208053691275 | test loss : 1.3974759578704834 | Train loss : 1.3560317754745483\n",
      "Looked at 0/593 samples.\n",
      "Looked at 12800/593 samples.\n",
      "Train loss:1.3177398443222046\n",
      "Test acc : 47.94043624161074 | test loss : 1.3398469686508179 | Train loss : 1.3177398443222046\n",
      "Looked at 0/593 samples.\n",
      "Looked at 12800/593 samples.\n",
      "Train loss:1.303940773010254\n",
      "Test acc : 46.35906040268456 | test loss : 1.3747233152389526 | Train loss : 1.303940773010254\n",
      "Looked at 0/593 samples.\n",
      "Looked at 12800/593 samples.\n",
      "Train loss:1.277944803237915\n",
      "Test acc : 47.48741610738255 | test loss : 1.3152506351470947 | Train loss : 1.277944803237915\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "\n",
    "    train_loss , train_acc = 0,0\n",
    "\n",
    "    for batch,(X,y) in enumerate(train_dataloader):\n",
    "\n",
    "        model.train()\n",
    "        \n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred,y)\n",
    "\n",
    "        train_loss+= loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch %400 ==0:\n",
    "          print(f\"Looked at {batch*len(X)}/{len(train_dataloader)} samples.\")\n",
    "\n",
    "\n",
    "    train_loss /= len(train_dataloader)\n",
    "\n",
    "    print(f\"Train loss:{train_loss}\")\n",
    "\n",
    "    ### Starting testing loop\n",
    "    test_loss, test_acc = 0,0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    with torch.inference_mode():\n",
    "\n",
    "        for batch,(X,y) in enumerate(test_dataloader):\n",
    "\n",
    "            y_pred = model(X)\n",
    "            loss = loss_fn(y_pred,y)\n",
    "            test_loss += loss\n",
    "\n",
    "            y_pred = y_pred.argmax(dim = 1)\n",
    "            \n",
    "            test_acc += accuracy_fn(y_pred,y)\n",
    "\n",
    "        test_acc= test_acc/len(test_dataloader)\n",
    "        test_loss/=len(test_dataloader)\n",
    "\n",
    "    print(f\"Test acc : {test_acc} | test loss : {test_loss} | Train loss : {train_loss}\")\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7193165b-55cf-4003-909a-0ec85741411f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((y[0] >=0.5).int() - y[0]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a12820-e87b-44d3-92bf-db5930f05f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
