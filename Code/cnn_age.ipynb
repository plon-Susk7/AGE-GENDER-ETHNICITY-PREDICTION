{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1403617d-2a00-48ca-8bdd-0a65beb34238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1+cu117'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "82d5f25e-aa92-4d67-8715-408cbfe83a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50_0_0_20170117135034485.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>55_0_3_20170119171117830.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12_0_4_20170103201607807.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40_0_0_20170117172519480.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>39_1_3_20170104233629347.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23703</th>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65_0_0_20170111200641250.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23704</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26_1_0_20170116234741431.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23705</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55_0_0_20170120140655585.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23706</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60_1_0_20170110122614299.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23707</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38_0_1_20170116200942002.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23705 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age gender race                                   path\n",
       "0      50      0    0  50_0_0_20170117135034485.jpg.chip.jpg\n",
       "1      55      0    3  55_0_3_20170119171117830.jpg.chip.jpg\n",
       "2      12      0    4  12_0_4_20170103201607807.jpg.chip.jpg\n",
       "3      40      0    0  40_0_0_20170117172519480.jpg.chip.jpg\n",
       "4      39      1    3  39_1_3_20170104233629347.jpg.chip.jpg\n",
       "...    ..    ...  ...                                    ...\n",
       "23703  65      0    0  65_0_0_20170111200641250.jpg.chip.jpg\n",
       "23704  26      1    0  26_1_0_20170116234741431.jpg.chip.jpg\n",
       "23705  55      0    0  55_0_0_20170120140655585.jpg.chip.jpg\n",
       "23706  60      1    0  60_1_0_20170110122614299.jpg.chip.jpg\n",
       "23707  38      0    1  38_0_1_20170116200942002.jpg.chip.jpg\n",
       "\n",
       "[23705 rows x 4 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from helper import get_dataframe\n",
    "\n",
    "df = get_dataframe('UTKFace')\n",
    "\n",
    "valid_values = ['0', '1', '2', '3', '4']\n",
    "\n",
    "df= df[df['race'].isin(valid_values)]\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2cc92b19-5a41-45cd-932f-90ca5ff7ecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating custom dataset\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self,path,labels,transfrom=None):\n",
    "        self.img_dir = path\n",
    "        self.img_labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        img_path = os.path.join(self.img_dir,self.img_labels.iloc[idx,0])\n",
    "        image = read_image(img_path)\n",
    "        label = list(map(int, self.img_labels.iloc[idx, 1]))\n",
    "        # label = list(map(int, map(float, self.img_labels.iloc[idx, 1])))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        \n",
    "        return image,label\n",
    "\n",
    "# Here normalization component was a standard found from the internet\n",
    "\n",
    "transform = transforms.Compose([  \n",
    "    transforms.ToPILImage(),\n",
    "    # transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((32, 32)),  # Resize the image to 28x28 pixels\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean=[0.485], std=[0.229])  # Normalize image (for grayscale)\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e88203ad-4a8b-4243-9456-1f69207301d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['26', '53', '17', '55', '35', '40', '25', '21', '24', '1', '15',\n",
       "       '23', '27', '9', '31', '54', '28', '30', '19', '50', '29', '37',\n",
       "       '22', '45', '3', '34', '58', '18', '14', '36', '2', '5', '52',\n",
       "       '43', '42', '110', '60', '74', '32', '70', '4', '41', '69', '66',\n",
       "       '20', '73', '8', '90', '48', '6', '81', '75', '7', '13', '71',\n",
       "       '57', '65', '61', '63', '39', '10', '72', '79', '85', '56', '47',\n",
       "       '80', '33', '12', '51', '46', '89', '16', '38', '86', '67', '59',\n",
       "       '78', '11', '82', '62', '44', '49', '64', '68', '76', '88', '77',\n",
       "       '96', '83', '84', '91', '100', '116', '115', '92', '87', '95',\n",
       "       '93', '105', '99', '103', '101', '111'], dtype=object)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['path'], df['age'], test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "training_data = pd.concat([X_train,y_train],axis=1)\n",
    "\n",
    "testing_data = pd.concat([X_test,y_test],axis=1)\n",
    "\n",
    "training_data['age'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f59c6a09-0862-4783-9bf9-6ac4c5f94bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = CustomDataset('UTKFace', training_data, transform)\n",
    "testing_dataset = CustomDataset('UTKFace', testing_data, transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3fc3fcd1-8b4e-47a5-b39d-0931442451c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(testing_dataset, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1df0f123-fcfb-4cbb-ba09-5370a79dc339",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "each element in list of batch should be of equal size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;66;03m# Test column\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:138\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    136\u001b[0m elem_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mnext\u001b[39m(it))\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(elem) \u001b[38;5;241m==\u001b[39m elem_size \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m it):\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meach element in list of batch should be of equal size\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n",
      "\u001b[0;31mRuntimeError\u001b[0m: each element in list of batch should be of equal size"
     ]
    }
   ],
   "source": [
    "next(iter(train_dataloader))[0].shape# Test column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce52dfda-db90-41f7-a1c2-30a5810942d2",
   "metadata": {},
   "source": [
    "### Creating TinyVGG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8650c881-2ce2-4bab-a01f-fa2e424c74c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "  def __init__(self,input_shape:int,hidden_units:int,output_shape:int):\n",
    "    super().__init__()\n",
    "    self.conv_block_1 = nn.Sequential(\n",
    "        nn.Conv2d(input_shape,hidden_units,kernel_size = 3,stride = 1,padding = 1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(hidden_units,hidden_units,kernel_size=3,stride=1,padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=3)\n",
    "    )\n",
    "\n",
    "    self.conv_block_2 = nn.Sequential(\n",
    "        nn.Conv2d(hidden_units,hidden_units,kernel_size = 3,stride = 1,padding = 1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(hidden_units,hidden_units,kernel_size=3,stride=1,padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2)\n",
    "    )\n",
    "\n",
    "    self.classifier = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(in_features=25*10,\n",
    "                  out_features=output_shape)\n",
    "    )\n",
    "\n",
    "\n",
    "  def forward(self,x):\n",
    "\n",
    "    x = self.conv_block_1(x)\n",
    "    x = self.conv_block_2(x)\n",
    "    x = self.classifier(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "57292e6a-aa8e-4122-bdf3-cad6deff6abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d64f1e63-26b5-4aaf-9e27-482b5fd163d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating model and defining function\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = 'cpu'\n",
    "model = Model(3,10,5)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params = model.parameters(),\n",
    "                            lr=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f39c1090-08fb-4f31-b428-2a0af7f18d62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f656652979547d2ad411bf5e07c9202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 0/593 samples.\n",
      "Looked at 12800/593 samples.\n",
      "Train loss:1.2973315715789795\n",
      "Test acc : 55.310402684563755 | test loss : 1.1629858016967773 | Train loss : 1.2973315715789795\n",
      "Looked at 0/593 samples.\n",
      "Looked at 12800/593 samples.\n",
      "Train loss:1.0214494466781616\n",
      "Test acc : 66.04865771812081 | test loss : 0.9412874579429626 | Train loss : 1.0214494466781616\n",
      "Looked at 0/593 samples.\n",
      "Looked at 12800/593 samples.\n",
      "Train loss:0.895909309387207\n",
      "Test acc : 70.62080536912751 | test loss : 0.8422528505325317 | Train loss : 0.895909309387207\n",
      "Looked at 0/593 samples.\n",
      "Looked at 12800/593 samples.\n",
      "Train loss:0.8454598188400269\n",
      "Test acc : 63.76258389261745 | test loss : 1.000044345855713 | Train loss : 0.8454598188400269\n",
      "Looked at 0/593 samples.\n",
      "Looked at 12800/593 samples.\n",
      "Train loss:0.8187004327774048\n",
      "Test acc : 72.26510067114094 | test loss : 0.8040850758552551 | Train loss : 0.8187004327774048\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "\n",
    "    train_loss , train_acc = 0,0\n",
    "\n",
    "    for batch,(X,y) in enumerate(train_dataloader):\n",
    "\n",
    "        model.train()\n",
    "        \n",
    "        y_pred = model(X)\n",
    "\n",
    "        loss = loss_fn(y_pred,y[0])\n",
    "\n",
    "        train_loss+= loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch %400 ==0:\n",
    "          print(f\"Looked at {batch*len(X)}/{len(train_dataloader)} samples.\")\n",
    "\n",
    "\n",
    "    train_loss /= len(train_dataloader)\n",
    "\n",
    "    print(f\"Train loss:{train_loss}\")\n",
    "\n",
    "    ### Starting testing loop\n",
    "    test_loss, test_acc = 0,0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    with torch.inference_mode():\n",
    "\n",
    "        for batch,(X,y) in enumerate(test_dataloader):\n",
    "\n",
    "            y_pred = model(X)\n",
    "            loss = loss_fn(y_pred,y[0])\n",
    "            test_loss += loss\n",
    "\n",
    "            y_pred = y_pred.argmax(dim = 1)\n",
    "            \n",
    "            test_acc += accuracy_fn(y_pred,y[0])\n",
    "\n",
    "        test_acc= test_acc/len(test_dataloader)\n",
    "        test_loss/=len(test_dataloader)\n",
    "\n",
    "    print(f\"Test acc : {test_acc} | test loss : {test_loss} | Train loss : {train_loss}\")\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7193165b-55cf-4003-909a-0ec85741411f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((y[0] >=0.5).int() - y[0]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a12820-e87b-44d3-92bf-db5930f05f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
