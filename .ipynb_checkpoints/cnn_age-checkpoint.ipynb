{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1403617d-2a00-48ca-8bdd-0a65beb34238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1+cu117'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "82d5f25e-aa92-4d67-8715-408cbfe83a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50_0_0_20170117135034485.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>55_0_3_20170119171117830.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12_0_4_20170103201607807.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40_0_0_20170117172519480.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>39_1_3_20170104233629347.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23703</th>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65_0_0_20170111200641250.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23704</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26_1_0_20170116234741431.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23705</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55_0_0_20170120140655585.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23706</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60_1_0_20170110122614299.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23707</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38_0_1_20170116200942002.jpg.chip.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23705 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age gender race                                   path\n",
       "0      50      0    0  50_0_0_20170117135034485.jpg.chip.jpg\n",
       "1      55      0    3  55_0_3_20170119171117830.jpg.chip.jpg\n",
       "2      12      0    4  12_0_4_20170103201607807.jpg.chip.jpg\n",
       "3      40      0    0  40_0_0_20170117172519480.jpg.chip.jpg\n",
       "4      39      1    3  39_1_3_20170104233629347.jpg.chip.jpg\n",
       "...    ..    ...  ...                                    ...\n",
       "23703  65      0    0  65_0_0_20170111200641250.jpg.chip.jpg\n",
       "23704  26      1    0  26_1_0_20170116234741431.jpg.chip.jpg\n",
       "23705  55      0    0  55_0_0_20170120140655585.jpg.chip.jpg\n",
       "23706  60      1    0  60_1_0_20170110122614299.jpg.chip.jpg\n",
       "23707  38      0    1  38_0_1_20170116200942002.jpg.chip.jpg\n",
       "\n",
       "[23705 rows x 4 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from helper import get_dataframe\n",
    "\n",
    "df = get_dataframe('UTKFace')\n",
    "\n",
    "valid_values = ['0', '1', '2', '3', '4']\n",
    "\n",
    "df= df[df['race'].isin(valid_values)]\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2cc92b19-5a41-45cd-932f-90ca5ff7ecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating custom dataset\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self,path,labels,transfrom=None):\n",
    "        self.img_dir = path\n",
    "        self.img_labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        img_path = os.path.join(self.img_dir,self.img_labels.iloc[idx,0])\n",
    "        image = read_image(img_path)\n",
    "        label = list(map(int, self.img_labels.iloc[idx, 1]))\n",
    "        # label = list(map(int, map(float, self.img_labels.iloc[idx, 1])))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        \n",
    "        return image,label\n",
    "\n",
    "# Here normalization component was a standard found from the internet\n",
    "\n",
    "transform = transforms.Compose([  \n",
    "    transforms.ToPILImage(),\n",
    "    # transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((48, 28)),  # Resize the image to 28x28 pixels\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean=[0.485], std=[0.229])  # Normalize image (for grayscale)\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e88203ad-4a8b-4243-9456-1f69207301d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '3', '4', '2'], dtype=object)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['path'], df['race'], test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "training_data = pd.concat([X_train,y_train],axis=1)\n",
    "\n",
    "testing_data = pd.concat([X_test,y_test],axis=1)\n",
    "\n",
    "training_data['race'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f59c6a09-0862-4783-9bf9-6ac4c5f94bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = CustomDataset('UTKFace', training_data, transform)\n",
    "testing_dataset = CustomDataset('UTKFace', testing_data, transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3fc3fcd1-8b4e-47a5-b39d-0931442451c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(testing_dataset, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1df0f123-fcfb-4cbb-ba09-5370a79dc339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 48, 48])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))[0].shape# Test column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce52dfda-db90-41f7-a1c2-30a5810942d2",
   "metadata": {},
   "source": [
    "### Creating TinyVGG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8650c881-2ce2-4bab-a01f-fa2e424c74c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "  def __init__(self,input_shape:int,hidden_units:int,output_shape:int):\n",
    "    super().__init__()\n",
    "    self.conv_block_1 = nn.Sequential(\n",
    "        nn.Conv2d(input_shape,hidden_units,kernel_size = 3,stride = 1,padding = 1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(hidden_units,hidden_units,kernel_size=3,stride=1,padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=3)\n",
    "    )\n",
    "\n",
    "    self.conv_block_2 = nn.Sequential(\n",
    "        nn.Conv2d(hidden_units,hidden_units,kernel_size = 3,stride = 1,padding = 1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(hidden_units,hidden_units,kernel_size=3,stride=1,padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2)\n",
    "    )\n",
    "\n",
    "    self.classifier = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(in_features=64*10,\n",
    "                  out_features=output_shape)\n",
    "    )\n",
    "\n",
    "\n",
    "  def forward(self,x):\n",
    "\n",
    "    x = self.conv_block_1(x)\n",
    "    x = self.conv_block_2(x)\n",
    "    x = self.classifier(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "57292e6a-aa8e-4122-bdf3-cad6deff6abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "    \"\"\"Calculates accuracy between truth labels and predictions.\n",
    "\n",
    "    Args:\n",
    "        y_true (torch.Tensor): Truth labels for predictions.\n",
    "        y_pred (torch.Tensor): Predictions to be compared to predictions.\n",
    "\n",
    "    Returns:\n",
    "        [torch.float]: Accuracy value between y_true and y_pred, e.g. 78.45\n",
    "    \"\"\"\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d64f1e63-26b5-4aaf-9e27-482b5fd163d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating model and defining function\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = 'cpu'\n",
    "model = Model(3,10,7)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params = model.parameters(),\n",
    "                            lr=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f39c1090-08fb-4f31-b428-2a0af7f18d62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1142525de11b4490b76be75b9752b596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 0/593 samples.\n",
      "Looked at 12800/593 samples.\n",
      "Train loss:1.3185912370681763\n",
      "Test acc : 59.685402684563755 | test loss : 1.1147598028182983 | Train loss : 1.3185912370681763\n",
      "Looked at 0/593 samples.\n",
      "Looked at 12800/593 samples.\n",
      "Train loss:0.9527029991149902\n",
      "Test acc : 58.93875838926174 | test loss : 1.095764398574829 | Train loss : 0.9527029991149902\n",
      "Looked at 0/593 samples.\n",
      "Looked at 12800/593 samples.\n",
      "Train loss:0.861150324344635\n",
      "Test acc : 69.81124161073825 | test loss : 0.8660730719566345 | Train loss : 0.861150324344635\n",
      "Looked at 0/593 samples.\n",
      "Looked at 12800/593 samples.\n",
      "Train loss:0.8161510825157166\n",
      "Test acc : 63.62835570469799 | test loss : 0.990710973739624 | Train loss : 0.8161510825157166\n",
      "Looked at 0/593 samples.\n",
      "Looked at 12800/593 samples.\n",
      "Train loss:0.7961120009422302\n",
      "Test acc : 69.8993288590604 | test loss : 0.850050151348114 | Train loss : 0.7961120009422302\n",
      "Looked at 0/593 samples.\n",
      "Looked at 12800/593 samples.\n",
      "Train loss:0.7825530171394348\n",
      "Test acc : 71.01929530201342 | test loss : 0.8108215928077698 | Train loss : 0.7825530171394348\n",
      "Looked at 0/593 samples.\n",
      "Looked at 12800/593 samples.\n",
      "Train loss:0.7643788456916809\n",
      "Test acc : 69.90771812080537 | test loss : 0.8436666131019592 | Train loss : 0.7643788456916809\n",
      "Looked at 0/593 samples.\n",
      "Looked at 12800/593 samples.\n",
      "Train loss:0.7555649876594543\n",
      "Test acc : 72.01342281879195 | test loss : 0.7909145951271057 | Train loss : 0.7555649876594543\n",
      "Looked at 0/593 samples.\n",
      "Looked at 12800/593 samples.\n",
      "Train loss:0.7538710236549377\n",
      "Test acc : 70.65436241610739 | test loss : 0.8228932619094849 | Train loss : 0.7538710236549377\n",
      "Looked at 0/593 samples.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(EPOCHS)):\n\u001b[1;32m      9\u001b[0m     train_loss , train_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch,(X,y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n\u001b[1;32m     13\u001b[0m         model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     15\u001b[0m         y_pred \u001b[38;5;241m=\u001b[39m model(X)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[55], line 19\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m,idx):\n\u001b[1;32m     18\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_dir,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_labels\u001b[38;5;241m.\u001b[39miloc[idx,\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 19\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mread_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_labels\u001b[38;5;241m.\u001b[39miloc[idx, \u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# label = list(map(int, map(float, self.img_labels.iloc[idx, 1])))\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/io/image.py:259\u001b[0m, in \u001b[0;36mread_image\u001b[0;34m(path, mode)\u001b[0m\n\u001b[1;32m    257\u001b[0m     _log_api_usage_once(read_image)\n\u001b[1;32m    258\u001b[0m data \u001b[38;5;241m=\u001b[39m read_file(path)\n\u001b[0;32m--> 259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdecode_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/io/image.py:236\u001b[0m, in \u001b[0;36mdecode_image\u001b[0;34m(input, mode)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_tracing():\n\u001b[1;32m    235\u001b[0m     _log_api_usage_once(decode_image)\n\u001b[0;32m--> 236\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_image\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_ops.py:502\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    498\u001b[0m     \u001b[38;5;66;03m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;66;03m# is still callable from JIT\u001b[39;00m\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;66;03m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;66;03m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[0;32m--> 502\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "\n",
    "    train_loss , train_acc = 0,0\n",
    "\n",
    "    for batch,(X,y) in enumerate(train_dataloader):\n",
    "\n",
    "        model.train()\n",
    "        \n",
    "        y_pred = model(X)\n",
    "\n",
    "        loss = loss_fn(y_pred,y[0])\n",
    "\n",
    "        train_loss+= loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch %400 ==0:\n",
    "          print(f\"Looked at {batch*len(X)}/{len(train_dataloader)} samples.\")\n",
    "\n",
    "\n",
    "    train_loss /= len(train_dataloader)\n",
    "\n",
    "    print(f\"Train loss:{train_loss}\")\n",
    "\n",
    "    ### Starting testing loop\n",
    "    test_loss, test_acc = 0,0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    with torch.inference_mode():\n",
    "\n",
    "        for batch,(X,y) in enumerate(test_dataloader):\n",
    "\n",
    "            y_pred = model(X)\n",
    "            loss = loss_fn(y_pred,y[0])\n",
    "            test_loss += loss\n",
    "\n",
    "            y_pred = y_pred.argmax(dim = 1)\n",
    "            \n",
    "            test_acc += accuracy_fn(y_pred,y[0])\n",
    "\n",
    "        test_acc= test_acc/len(test_dataloader)\n",
    "        test_loss/=len(test_dataloader)\n",
    "\n",
    "    print(f\"Test acc : {test_acc} | test loss : {test_loss} | Train loss : {train_loss}\")\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7193165b-55cf-4003-909a-0ec85741411f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((y[0] >=0.5).int() - y[0]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a12820-e87b-44d3-92bf-db5930f05f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
